{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Funzione per estrarre e convertire i valori dell'ottava colonna in liste di float\n",
    "def get_eight_column_values(df, type_val, module_val, name_val):\n",
    "    filtered_df = df[(df['type'] == type_val) & (df['module'] == module_val) & (df['name'] == name_val)]\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    values = filtered_df.iloc[:, 7].str.split().apply(lambda x: list(map(float, x)))\n",
    "    return values.explode().astype(float).values\n",
    "\n",
    "# Funzione per estrarre e convertire i valori della settima colonna in liste di float\n",
    "def get_seventh_column_values(df, type_val, module_val, name_val):\n",
    "    filtered_df = df[(df['type'] == type_val) & (df['module'] == module_val) & (df['name'] == name_val)]\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    values = filtered_df.iloc[:, 6].str.split().apply(lambda x: list(map(float, x)))\n",
    "    return values.explode().astype(float).values\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza t-student\n",
    "def t_student_confidence_interval(data, confidence=0.95):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza naive\n",
    "def naive_confidence_interval(data, confidence=0.95):\n",
    "    mean = np.mean(data)\n",
    "    margin = mean * (1 - confidence)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza normale\n",
    "def normal_confidence_interval(data, confidence=0.95):\n",
    "    mean = np.mean(data)\n",
    "    std_error = stats.sem(data)  # Standard error of the mean\n",
    "    z_value = stats.norm.ppf(1 - (1 - confidence) / 2)\n",
    "    margin = z_value * std_error\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Funzione per rimuovere '_vec' dalla fine del nome del file\n",
    "def remove_vec_suffix(file_name):\n",
    "    if file_name.endswith('_vec.csv'):\n",
    "        return file_name[:-8]\n",
    "    else:\n",
    "        return file_name\n",
    "\n",
    "# Funzione per ottenere il numero finale dal nome del file\n",
    "def get_file_number(file_name):\n",
    "    match = re.search(r'\\d+$', file_name)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return 0  # Se non viene trovato nessun numero, restituisci 0\n",
    "\n",
    "# Funzione per analizzare un singolo file CSV\n",
    "def analyze_csv(file_path, ignored_files, results):\n",
    "    df = pd.read_csv(file_path)\n",
    "    description = df[df['attrname'] == 'description']['attrvalue'].values\n",
    "    description = description[0] if len(description) > 0 else \"N/A\"\n",
    "\n",
    "    is_N = any(\"N=1\" in val for val in df[df['attrname'] == 'description']['attrvalue'].values)\n",
    "\n",
    "    pDistribution = get_eight_column_values(df, \"vector\", \"TandemQueueSystem.Server\", \"pDistribution\")\n",
    "    vDistribution = get_eight_column_values(df, \"vector\", \"TandemQueueSystem.Server\", \"vDistribution\")\n",
    "    lifeTime = get_eight_column_values(df, \"vector\", \"TandemQueueSystem.sink\", \"lifeTime:vector\")\n",
    "    lifeTime_arrival = get_seventh_column_values(df, \"vector\", \"TandemQueueSystem.sink\", \"lifeTime:vector\")\n",
    "    lifeTime_change_Q1 = get_seventh_column_values(df, \"vector\", \"TandemQueueSystem.Q1\", \"queueLength:vector\")\n",
    "    lifeTime_change_Q2 = get_seventh_column_values(df, \"vector\", \"TandemQueueSystem.Q2\", \"queueLength:vector\")\n",
    "\n",
    "    if pDistribution is None or vDistribution is None or lifeTime is None:\n",
    "        ignored_files.append((remove_vec_suffix(os.path.basename(file_path)), description))\n",
    "        return\n",
    "\n",
    "    min_length = min(len(pDistribution), len(vDistribution), len(lifeTime))\n",
    "    pDistribution = pDistribution[:min_length]\n",
    "    vDistribution = vDistribution[:min_length]\n",
    "    lifeTime = lifeTime[:min_length]\n",
    "\n",
    "    queueLength_Q1 = get_eight_column_values(df, \"vector\", \"TandemQueueSystem.Q1\", \"queueLength:vector\")\n",
    "    queueLength_Q2 = get_eight_column_values(df, \"vector\", \"TandemQueueSystem.Q2\", \"queueLength:vector\")\n",
    "\n",
    "    if is_N:\n",
    "        queueLength_Q2 = np.zeros(len(queueLength_Q1))\n",
    "    else: \n",
    "        if queueLength_Q1 is None or queueLength_Q2 is None:\n",
    "            ignored_files.append((remove_vec_suffix(os.path.basename(file_path)), description))\n",
    "            return\n",
    "\n",
    "    Cw = 1  # Definisci il valore di Cw\n",
    "\n",
    "    conf_levels = [0.95, 0.90, 0.85, 0.80]\n",
    "    lifeTime_stats_t_student = {}\n",
    "    U_values_stats_t_student = {}\n",
    "    utilization_Q1_stats_t_student = {}\n",
    "    utilization_Q2_stats_t_student = {}\n",
    "\n",
    "    lifeTime_stats_naive = {}\n",
    "    U_values_stats_naive = {}\n",
    "    utilization_Q1_stats_naive = {}\n",
    "    utilization_Q2_stats_naive = {}\n",
    "    \n",
    "    lifeTime_stats_normal = {}\n",
    "    U_values_stats_normal = {}\n",
    "    utilization_Q1_stats_normal = {}\n",
    "    utilization_Q2_stats_normal = {}\n",
    "\n",
    "    for conf in conf_levels:\n",
    "        # Calcoli t-student\n",
    "        mean_W_t, ci_low_W_t, ci_high_W_t = t_student_confidence_interval(lifeTime, confidence=conf)\n",
    "        lifeTime_stats_t_student[conf] = (mean_W_t, ci_low_W_t, ci_high_W_t)\n",
    "        \n",
    "        U_values = vDistribution - pDistribution - (Cw * lifeTime)\n",
    "        mean_U_t, ci_low_U_t, ci_high_U_t = t_student_confidence_interval(U_values, confidence=conf)\n",
    "        U_values_stats_t_student[conf] = (mean_U_t, ci_low_U_t, ci_high_U_t)\n",
    "\n",
    "        mean_utilization_Q1_t, ci_low_utilization_Q1_t, ci_high_utilization_Q1_t = t_student_confidence_interval(queueLength_Q1 / np.sum(queueLength_Q1), confidence=conf)\n",
    "        utilization_Q1_stats_t_student[conf] = (mean_utilization_Q1_t, ci_low_utilization_Q1_t, ci_high_utilization_Q1_t)\n",
    "\n",
    "        mean_utilization_Q2_t, ci_low_utilization_Q2_t, ci_high_utilization_Q2_t = t_student_confidence_interval(queueLength_Q2 / np.sum(queueLength_Q2), confidence=conf)\n",
    "        utilization_Q2_stats_t_student[conf] = (mean_utilization_Q2_t, ci_low_utilization_Q2_t, ci_high_utilization_Q2_t)\n",
    "\n",
    "        # Calcoli naive\n",
    "        mean_W_n, ci_low_W_n, ci_high_W_n = naive_confidence_interval(lifeTime, confidence=conf)\n",
    "        lifeTime_stats_naive[conf] = (mean_W_n, ci_low_W_n, ci_high_W_n)\n",
    "        \n",
    "        mean_U_n, ci_low_U_n, ci_high_U_n = naive_confidence_interval(U_values, confidence=conf)\n",
    "        U_values_stats_naive[conf] = (mean_U_n, ci_low_U_n, ci_high_U_n)\n",
    "\n",
    "        mean_utilization_Q1_n, ci_low_utilization_Q1_n, ci_high_utilization_Q1_n = naive_confidence_interval(queueLength_Q1 / np.sum(queueLength_Q1), confidence=conf)\n",
    "        utilization_Q1_stats_naive[conf] = (mean_utilization_Q1_n, ci_low_utilization_Q1_n, ci_high_utilization_Q1_n)\n",
    "\n",
    "        mean_utilization_Q2_n, ci_low_utilization_Q2_n, ci_high_utilization_Q2_n = naive_confidence_interval(queueLength_Q2 / np.sum(queueLength_Q2), confidence=conf)\n",
    "        utilization_Q2_stats_naive[conf] = (mean_utilization_Q2_n, ci_low_utilization_Q2_n, ci_high_utilization_Q2_n)\n",
    "\n",
    "        # Calcoli normale\n",
    "        mean_W_norm, ci_low_W_norm, ci_high_W_norm = normal_confidence_interval(lifeTime, confidence=conf)\n",
    "        lifeTime_stats_normal[conf] = (mean_W_norm, ci_low_W_norm, ci_high_W_norm)\n",
    "        \n",
    "        mean_U_norm, ci_low_U_norm, ci_high_U_norm = normal_confidence_interval(U_values, confidence=conf)\n",
    "        U_values_stats_normal[conf] = (mean_U_norm, ci_low_U_norm, ci_high_U_norm)\n",
    "\n",
    "        mean_utilization_Q1_norm, ci_low_utilization_Q1_norm, ci_high_utilization_Q1_norm = normal_confidence_interval(queueLength_Q1 / np.sum(queueLength_Q1), confidence=conf)\n",
    "        utilization_Q1_stats_normal[conf] = (mean_utilization_Q1_norm, ci_low_utilization_Q1_norm, ci_high_utilization_Q1_norm)\n",
    "\n",
    "        mean_utilization_Q2_norm, ci_low_utilization_Q2_norm, ci_high_utilization_Q2_norm = normal_confidence_interval(queueLength_Q2 / np.sum(queueLength_Q2), confidence=conf)\n",
    "        utilization_Q2_stats_normal[conf] = (mean_utilization_Q2_norm, ci_low_utilization_Q2_norm, ci_high_utilization_Q2_norm)\n",
    "\n",
    "    max_W = np.max(lifeTime)\n",
    "    min_W = np.min(lifeTime)\n",
    "\n",
    "    results.append({\n",
    "        \"File\": remove_vec_suffix(os.path.basename(file_path)),\n",
    "        \"File_Number\": get_file_number(remove_vec_suffix(os.path.basename(file_path))),\n",
    "        \"Description\": description,\n",
    "        \"max_W\": max_W,\n",
    "        \"min_W\": min_W,\n",
    "        **{f\"mean_W_t_student_{int(conf*100)}\": lifeTime_stats_t_student[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_W_t_student_{int(conf*100)}\": lifeTime_stats_t_student[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_W_t_student_{int(conf*100)}\": lifeTime_stats_t_student[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_U_t_student_{int(conf*100)}\": U_values_stats_t_student[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_U_t_student_{int(conf*100)}\": U_values_stats_t_student[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_U_t_student_{int(conf*100)}\": U_values_stats_t_student[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q1_t_student_{int(conf*100)}\": utilization_Q1_stats_t_student[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q1_t_student_{int(conf*100)}\": utilization_Q1_stats_t_student[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q1_t_student_{int(conf*100)}\": utilization_Q1_stats_t_student[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q2_t_student_{int(conf*100)}\": utilization_Q2_stats_t_student[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q2_t_student_{int(conf*100)}\": utilization_Q2_stats_t_student[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q2_t_student_{int(conf*100)}\": utilization_Q2_stats_t_student[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_W_naive_{int(conf*100)}\": lifeTime_stats_naive[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_W_naive_{int(conf*100)}\": lifeTime_stats_naive[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_W_naive_{int(conf*100)}\": lifeTime_stats_naive[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_U_naive_{int(conf*100)}\": U_values_stats_naive[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_U_naive_{int(conf*100)}\": U_values_stats_naive[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_U_naive_{int(conf*100)}\": U_values_stats_naive[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q1_naive_{int(conf*100)}\": utilization_Q1_stats_naive[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q1_naive_{int(conf*100)}\": utilization_Q1_stats_naive[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q1_naive_{int(conf*100)}\": utilization_Q1_stats_naive[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q2_naive_{int(conf*100)}\": utilization_Q2_stats_naive[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q2_naive_{int(conf*100)}\": utilization_Q2_stats_naive[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q2_naive_{int(conf*100)}\": utilization_Q2_stats_naive[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_W_normal_{int(conf*100)}\": lifeTime_stats_normal[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_W_normal_{int(conf*100)}\": lifeTime_stats_normal[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_W_normal_{int(conf*100)}\": lifeTime_stats_normal[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_U_normal_{int(conf*100)}\": U_values_stats_normal[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_U_normal_{int(conf*100)}\": U_values_stats_normal[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_U_normal_{int(conf*100)}\": U_values_stats_normal[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q1_normal_{int(conf*100)}\": utilization_Q1_stats_normal[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q1_normal_{int(conf*100)}\": utilization_Q1_stats_normal[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q1_normal_{int(conf*100)}\": utilization_Q1_stats_normal[conf][2] for conf in conf_levels},\n",
    "        **{f\"mean_utilization_Q2_normal_{int(conf*100)}\": utilization_Q2_stats_normal[conf][0] for conf in conf_levels},\n",
    "        **{f\"ci_low_utilization_Q2_normal_{int(conf*100)}\": utilization_Q2_stats_normal[conf][1] for conf in conf_levels},\n",
    "        **{f\"ci_high_utilization_Q2_normal_{int(conf*100)}\": utilization_Q2_stats_normal[conf][2] for conf in conf_levels},\n",
    "        \"mean_queueLength_Q1\": np.mean(queueLength_Q1),\n",
    "        \"mean_queueLength_Q2\": np.mean(queueLength_Q2),\n",
    "        \"lifeTime\": \",\".join(map(str, lifeTime)),\n",
    "        \"lifeTime_arrival\": \",\".join(map(str, lifeTime_arrival)),\n",
    "        \"queueLength_Q1\": \",\".join(map(str, queueLength_Q1)),\n",
    "        \"queueLength_Q2\": \",\".join(map(str, queueLength_Q2)),\n",
    "        \"lifeTime_change_Q1\": \",\".join(map(str, lifeTime_change_Q1)),\n",
    "        \"lifeTime_change_Q2\": \",\".join(map(str, lifeTime_change_Q2))\n",
    "    })\n",
    "\n",
    "# Funzione per analizzare tutti i file CSV in una directory\n",
    "def analyze_directory(directory_path):\n",
    "    ignored_files = []\n",
    "    results = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.csv') and not file_name.endswith('_sca.csv'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            analyze_csv(file_path, ignored_files, results)\n",
    "    \n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values(by='File_Number')  # Ordina per numero del file\n",
    "        results_df.drop(columns=['File_Number'], inplace=True)  # Rimuovi la colonna File_Number\n",
    "        results_df.to_csv(os.path.join('./results_summary_convalidation_3.csv'), index=False)\n",
    "    \n",
    "    if ignored_files:\n",
    "        ignored_files_sorted = sorted(ignored_files, key=lambda x: get_file_number(x[0]))  # Ordina gli ignorati per numero del file\n",
    "        ignored_df = pd.DataFrame(ignored_files_sorted, columns=['File', 'Description'])\n",
    "        ignored_df.to_csv(os.path.join('./ignored_files_convalidation_3.csv'), index=False)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "directory_path = './results_CSV_convalidation_3'\n",
    "analyze_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Carica il DataFrame dal file CSV\n",
    "df = pd.read_csv('./results_summary_convalidation_3.csv')\n",
    "\n",
    "df = df[df[\"File\"].str.contains(\"Config2\")]\n",
    "\n",
    "# Converti le colonne in liste di float\n",
    "df[\"queueLength_Q1\"] = df[\"queueLength_Q1\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"queueLength_Q2\"] = df[\"queueLength_Q2\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"lifeTime_change_Q1\"] = df[\"lifeTime_change_Q1\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "df[\"lifeTime_change_Q2\"] = df[\"lifeTime_change_Q2\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "\n",
    "# Dizionario per accumulare i valori di lt_diff per ogni simulazione e numero di utenti\n",
    "lt_diff_dict = {}\n",
    "\n",
    "# Itera su tutte le righe del DataFrame filtrato\n",
    "for index, row in df.iterrows():\n",
    "    UsersQ1 = row[\"queueLength_Q1\"]\n",
    "    UsersQ2 = row[\"queueLength_Q2\"]\n",
    "    TimesQ1 = row[\"lifeTime_change_Q1\"]\n",
    "    TimesQ2 = row[\"lifeTime_change_Q2\"]\n",
    "\n",
    "    # Funzione per ottenere il numero di utenti in un determinato momento\n",
    "    def get_user_count(times, users, time):\n",
    "        for i, t in enumerate(times):\n",
    "            if t == time:\n",
    "                return users[i]\n",
    "            elif t > time:\n",
    "                return users[i-1]\n",
    "        return users[-1]\n",
    "\n",
    "    # Combiniamo e ordiniamo i tempi\n",
    "    combined_times = sorted(set(TimesQ1 + TimesQ2))\n",
    "\n",
    "    # Calcoliamo i valori combinati degli utenti\n",
    "    UsersQ1_Q2 = []\n",
    "    for time in combined_times:\n",
    "        users_q1 = get_user_count(TimesQ1, UsersQ1, time)\n",
    "        users_q2 = get_user_count(TimesQ2, UsersQ2, time)\n",
    "        UsersQ1_Q2.append(users_q1 + users_q2)\n",
    "\n",
    "    # Calcolo delle differenze di tempo (lt_diff) per questa simulazione\n",
    "    sim_lt_diff = {}\n",
    "    for i in range(1, len(combined_times)):\n",
    "        lt_difference = combined_times[i] - combined_times[i-1]\n",
    "        key = UsersQ1_Q2[i-1]\n",
    "        if key not in sim_lt_diff:\n",
    "            sim_lt_diff[key] = 0\n",
    "        sim_lt_diff[key] += lt_difference\n",
    "\n",
    "    # Aggiungiamo i lt_diff di questa simulazione al dizionario generale\n",
    "    for key, value in sim_lt_diff.items():\n",
    "        if key not in lt_diff_dict:\n",
    "            lt_diff_dict[key] = []\n",
    "        lt_diff_dict[key].append(value)\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza di Student\n",
    "def t_student_confidence_interval(data, confidence=0.90):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Lista per accumulare i dati delle nuove righe\n",
    "new_data = []\n",
    "\n",
    "# Calcolo dell'intervallo di confidenza e creazione delle nuove righe\n",
    "for key, lt_diffs in lt_diff_dict.items():\n",
    "    mean, lower_bound, upper_bound = t_student_confidence_interval(lt_diffs)\n",
    "    verifica = 'x' if lower_bound <= mean <= upper_bound else ''\n",
    "    new_data.append({\n",
    "        \"agents_in_the_system\": key,\n",
    "        \"lt_difference\": mean,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"verifica\": verifica\n",
    "    })\n",
    "\n",
    "# Creazione del nuovo DataFrame dalle nuove righe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Funzione per stampare la somma totale di lt_differences\n",
    "def print_total_lt_difference(df):\n",
    "    total_lt_difference = df[\"lt_difference\"].sum()\n",
    "    print(f\"La somma totale di tutti i lt_differences è: {total_lt_difference}\")\n",
    "\n",
    "# Utilizzo della funzione\n",
    "print_total_lt_difference(new_df)\n",
    "\n",
    "# Salvataggio del DataFrame in un file CSV\n",
    "new_df.to_csv(\"users_times_Config2.csv\", index=False)\n",
    "\n",
    "# Visualizzazione del nuovo DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somma totale di tutti i lt_differences è: 10016.34482398942\n",
      "    agents_in_the_system  lt_difference  lower_bound  upper_bound verifica\n",
      "0                      0    4429.770966  4357.111879  4502.430052        x\n",
      "1                      1    1756.506426  1734.452486  1778.560366        x\n",
      "2                      2    1369.987108  1350.798149  1389.176067        x\n",
      "3                      3     955.754731   935.070644   976.438819        x\n",
      "4                      4     595.654726   575.500819   615.808633        x\n",
      "5                      5     355.099441   339.429840   370.769042        x\n",
      "6                      6     208.558717   194.370585   222.746849        x\n",
      "7                      7     126.587714   113.881403   139.294025        x\n",
      "8                      8      76.436567    65.367042    87.506092        x\n",
      "9                      9      47.837404    38.352879    57.321930        x\n",
      "10                    10      30.444115    23.330946    37.557285        x\n",
      "11                    11      17.685754    12.897938    22.473571        x\n",
      "12                    12      10.745135     7.298839    14.191431        x\n",
      "13                    13       6.888285     3.962567     9.814004        x\n",
      "14                    14       6.539092     3.784735     9.293448        x\n",
      "15                    15       6.667879     3.518403     9.817356        x\n",
      "16                    16       7.911468     3.989354    11.833583        x\n",
      "17                    17       3.450091     0.478303     6.421879        x\n",
      "18                    18       1.978931    -0.367913     4.325775        x\n",
      "19                    19       1.516283     1.064186     1.968380        x\n",
      "20                    20       0.323990          NaN          NaN         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stintipacchio/miniconda3/envs/inifile/lib/python3.12/site-packages/numpy/_core/_methods.py:218: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/stintipacchio/miniconda3/envs/inifile/lib/python3.12/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Carica il DataFrame dal file CSV\n",
    "df = pd.read_csv('./results_summary_convalidation_3.csv')\n",
    "\n",
    "df = df[df[\"File\"].str.contains(\"Config4\")]\n",
    "\n",
    "# Converti le colonne in liste di float\n",
    "df[\"queueLength_Q1\"] = df[\"queueLength_Q1\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"queueLength_Q2\"] = df[\"queueLength_Q2\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"lifeTime_change_Q1\"] = df[\"lifeTime_change_Q1\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "df[\"lifeTime_change_Q2\"] = df[\"lifeTime_change_Q2\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "\n",
    "# Dizionario per accumulare i valori di lt_diff per ogni simulazione e numero di utenti\n",
    "lt_diff_dict = {}\n",
    "\n",
    "# Itera su tutte le righe del DataFrame filtrato\n",
    "for index, row in df.iterrows():\n",
    "    UsersQ1 = row[\"queueLength_Q1\"]\n",
    "    UsersQ2 = row[\"queueLength_Q2\"]\n",
    "    TimesQ1 = row[\"lifeTime_change_Q1\"]\n",
    "    TimesQ2 = row[\"lifeTime_change_Q2\"]\n",
    "\n",
    "    # Funzione per ottenere il numero di utenti in un determinato momento\n",
    "    def get_user_count(times, users, time):\n",
    "        for i, t in enumerate(times):\n",
    "            if t == time:\n",
    "                return users[i]\n",
    "            elif t > time:\n",
    "                return users[i-1]\n",
    "        return users[-1]\n",
    "\n",
    "    # Combiniamo e ordiniamo i tempi\n",
    "    combined_times = sorted(set(TimesQ1 + TimesQ2))\n",
    "\n",
    "    # Calcoliamo i valori combinati degli utenti\n",
    "    UsersQ1_Q2 = []\n",
    "    for time in combined_times:\n",
    "        users_q1 = get_user_count(TimesQ1, UsersQ1, time)\n",
    "        users_q2 = get_user_count(TimesQ2, UsersQ2, time)\n",
    "        UsersQ1_Q2.append(users_q1 + users_q2)\n",
    "\n",
    "    # Calcolo delle differenze di tempo (lt_diff) per questa simulazione\n",
    "    sim_lt_diff = {}\n",
    "    for i in range(1, len(combined_times)):\n",
    "        lt_difference = combined_times[i] - combined_times[i-1]\n",
    "        key = UsersQ1_Q2[i-1]\n",
    "        if key not in sim_lt_diff:\n",
    "            sim_lt_diff[key] = 0\n",
    "        sim_lt_diff[key] += lt_difference\n",
    "\n",
    "    # Aggiungiamo i lt_diff di questa simulazione al dizionario generale\n",
    "    for key, value in sim_lt_diff.items():\n",
    "        if key not in lt_diff_dict:\n",
    "            lt_diff_dict[key] = []\n",
    "        lt_diff_dict[key].append(value)\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza di Student\n",
    "def t_student_confidence_interval(data, confidence=0.90):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Lista per accumulare i dati delle nuove righe\n",
    "new_data = []\n",
    "\n",
    "# Calcolo dell'intervallo di confidenza e creazione delle nuove righe\n",
    "for key, lt_diffs in lt_diff_dict.items():\n",
    "    mean, lower_bound, upper_bound = t_student_confidence_interval(lt_diffs)\n",
    "    verifica = 'x' if lower_bound <= mean <= upper_bound else ''\n",
    "    new_data.append({\n",
    "        \"agents_in_the_system\": key,\n",
    "        \"lt_difference\": mean,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"verifica\": verifica\n",
    "    })\n",
    "\n",
    "# Creazione del nuovo DataFrame dalle nuove righe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Funzione per stampare la somma totale di lt_differences\n",
    "def print_total_lt_difference(df):\n",
    "    total_lt_difference = df[\"lt_difference\"].sum()\n",
    "    print(f\"La somma totale di tutti i lt_differences è: {total_lt_difference}\")\n",
    "\n",
    "# Utilizzo della funzione\n",
    "print_total_lt_difference(new_df)\n",
    "\n",
    "# Salvataggio del DataFrame in un file CSV\n",
    "new_df.to_csv(\"users_times_Config4.csv\", index=False)\n",
    "\n",
    "# Visualizzazione del nuovo DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somma totale di tutti i lt_differences è: 10005.716179339344\n",
      "    agents_in_the_system  lt_difference  lower_bound  upper_bound verifica\n",
      "0                      0    5868.233158  5814.081200  5922.385115        x\n",
      "1                      1    1726.391317  1710.837695  1741.944939        x\n",
      "2                      2    1137.909612  1120.023911  1155.795313        x\n",
      "3                      3     661.210396   644.460210   677.960582        x\n",
      "4                      4     324.527908   310.661485   338.394332        x\n",
      "5                      5     150.107319   139.644812   160.569826        x\n",
      "6                      6      71.131172    63.656684    78.605660        x\n",
      "7                      7      32.978727    28.314999    37.642456        x\n",
      "8                      8      13.707761    11.015563    16.399958        x\n",
      "9                      9       6.232831     4.343204     8.122458        x\n",
      "10                    10       4.060238     2.326424     5.794051        x\n",
      "11                    11       2.889780     1.656047     4.123514        x\n",
      "12                    12       2.068259     0.828921     3.307597        x\n",
      "13                    13       2.336497     0.286725     4.386268        x\n",
      "14                    14       1.606488    -0.164911     3.377886        x\n",
      "15                    15       0.324717    -0.274528     0.923962        x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Carica il DataFrame dal file CSV\n",
    "df = pd.read_csv('./results_summary_convalidation_3.csv')\n",
    "\n",
    "df = df[df[\"File\"].str.contains(\"Config6\")]\n",
    "\n",
    "# Converti le colonne in liste di float\n",
    "df[\"queueLength_Q1\"] = df[\"queueLength_Q1\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"queueLength_Q2\"] = df[\"queueLength_Q2\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"lifeTime_change_Q1\"] = df[\"lifeTime_change_Q1\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "df[\"lifeTime_change_Q2\"] = df[\"lifeTime_change_Q2\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "\n",
    "# Dizionario per accumulare i valori di lt_diff per ogni simulazione e numero di utenti\n",
    "lt_diff_dict = {}\n",
    "\n",
    "# Itera su tutte le righe del DataFrame filtrato\n",
    "for index, row in df.iterrows():\n",
    "    UsersQ1 = row[\"queueLength_Q1\"]\n",
    "    UsersQ2 = row[\"queueLength_Q2\"]\n",
    "    TimesQ1 = row[\"lifeTime_change_Q1\"]\n",
    "    TimesQ2 = row[\"lifeTime_change_Q2\"]\n",
    "\n",
    "    # Funzione per ottenere il numero di utenti in un determinato momento\n",
    "    def get_user_count(times, users, time):\n",
    "        for i, t in enumerate(times):\n",
    "            if t == time:\n",
    "                return users[i]\n",
    "            elif t > time:\n",
    "                return users[i-1]\n",
    "        return users[-1]\n",
    "\n",
    "    # Combiniamo e ordiniamo i tempi\n",
    "    combined_times = sorted(set(TimesQ1 + TimesQ2))\n",
    "\n",
    "    # Calcoliamo i valori combinati degli utenti\n",
    "    UsersQ1_Q2 = []\n",
    "    for time in combined_times:\n",
    "        users_q1 = get_user_count(TimesQ1, UsersQ1, time)\n",
    "        users_q2 = get_user_count(TimesQ2, UsersQ2, time)\n",
    "        UsersQ1_Q2.append(users_q1 + users_q2)\n",
    "\n",
    "    # Calcolo delle differenze di tempo (lt_diff) per questa simulazione\n",
    "    sim_lt_diff = {}\n",
    "    for i in range(1, len(combined_times)):\n",
    "        lt_difference = combined_times[i] - combined_times[i-1]\n",
    "        key = UsersQ1_Q2[i-1]\n",
    "        if key not in sim_lt_diff:\n",
    "            sim_lt_diff[key] = 0\n",
    "        sim_lt_diff[key] += lt_difference\n",
    "\n",
    "    # Aggiungiamo i lt_diff di questa simulazione al dizionario generale\n",
    "    for key, value in sim_lt_diff.items():\n",
    "        if key not in lt_diff_dict:\n",
    "            lt_diff_dict[key] = []\n",
    "        lt_diff_dict[key].append(value)\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza di Student\n",
    "def t_student_confidence_interval(data, confidence=0.90):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Lista per accumulare i dati delle nuove righe\n",
    "new_data = []\n",
    "\n",
    "# Calcolo dell'intervallo di confidenza e creazione delle nuove righe\n",
    "for key, lt_diffs in lt_diff_dict.items():\n",
    "    mean, lower_bound, upper_bound = t_student_confidence_interval(lt_diffs)\n",
    "    verifica = 'x' if lower_bound <= mean <= upper_bound else ''\n",
    "    new_data.append({\n",
    "        \"agents_in_the_system\": key,\n",
    "        \"lt_difference\": mean,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"verifica\": verifica\n",
    "    })\n",
    "\n",
    "# Creazione del nuovo DataFrame dalle nuove righe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Funzione per stampare la somma totale di lt_differences\n",
    "def print_total_lt_difference(df):\n",
    "    total_lt_difference = df[\"lt_difference\"].sum()\n",
    "    print(f\"La somma totale di tutti i lt_differences è: {total_lt_difference}\")\n",
    "\n",
    "# Utilizzo della funzione\n",
    "print_total_lt_difference(new_df)\n",
    "\n",
    "# Salvataggio del DataFrame in un file CSV\n",
    "new_df.to_csv(\"users_times_Config6.csv\", index=False)\n",
    "\n",
    "# Visualizzazione del nuovo DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somma totale di tutti i lt_differences è: 10007.804964013245\n",
      "    agents_in_the_system  lt_difference  lower_bound  upper_bound verifica\n",
      "0                      0    6899.833141  6855.577762  6944.088520        x\n",
      "1                      1    1514.747797  1499.437699  1530.057895        x\n",
      "2                      2     874.815177   859.952477   889.677876        x\n",
      "3                      3     437.433141   424.362161   450.504120        x\n",
      "4                      4     174.323865   164.927974   183.719756        x\n",
      "5                      5      62.599899    57.737008    67.462790        x\n",
      "6                      6      22.318745    19.855750    24.781740        x\n",
      "7                      7       7.108501     5.568115     8.648887        x\n",
      "8                      8       3.036412     2.024410     4.048413        x\n",
      "9                      9       1.718821     0.869090     2.568553        x\n",
      "10                    10       1.341263     0.132039     2.550488        x\n",
      "11                    11       2.057782    -0.353037     4.468601        x\n",
      "12                    12       2.816184   -11.231434    16.863802        x\n",
      "13                    13       2.887206          NaN          NaN         \n",
      "14                    14       0.767029          NaN          NaN         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stintipacchio/miniconda3/envs/inifile/lib/python3.12/site-packages/numpy/_core/_methods.py:218: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/stintipacchio/miniconda3/envs/inifile/lib/python3.12/site-packages/numpy/_core/_methods.py:210: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Carica il DataFrame dal file CSV\n",
    "df = pd.read_csv('./results_summary_convalidation_3.csv')\n",
    "\n",
    "df = df[df[\"File\"].str.contains(\"Config8\")]\n",
    "\n",
    "# Converti le colonne in liste di float\n",
    "df[\"queueLength_Q1\"] = df[\"queueLength_Q1\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"queueLength_Q2\"] = df[\"queueLength_Q2\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"lifeTime_change_Q1\"] = df[\"lifeTime_change_Q1\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "df[\"lifeTime_change_Q2\"] = df[\"lifeTime_change_Q2\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "\n",
    "# Dizionario per accumulare i valori di lt_diff per ogni simulazione e numero di utenti\n",
    "lt_diff_dict = {}\n",
    "\n",
    "# Itera su tutte le righe del DataFrame filtrato\n",
    "for index, row in df.iterrows():\n",
    "    UsersQ1 = row[\"queueLength_Q1\"]\n",
    "    UsersQ2 = row[\"queueLength_Q2\"]\n",
    "    TimesQ1 = row[\"lifeTime_change_Q1\"]\n",
    "    TimesQ2 = row[\"lifeTime_change_Q2\"]\n",
    "\n",
    "    # Funzione per ottenere il numero di utenti in un determinato momento\n",
    "    def get_user_count(times, users, time):\n",
    "        for i, t in enumerate(times):\n",
    "            if t == time:\n",
    "                return users[i]\n",
    "            elif t > time:\n",
    "                return users[i-1]\n",
    "        return users[-1]\n",
    "\n",
    "    # Combiniamo e ordiniamo i tempi\n",
    "    combined_times = sorted(set(TimesQ1 + TimesQ2))\n",
    "\n",
    "    # Calcoliamo i valori combinati degli utenti\n",
    "    UsersQ1_Q2 = []\n",
    "    for time in combined_times:\n",
    "        users_q1 = get_user_count(TimesQ1, UsersQ1, time)\n",
    "        users_q2 = get_user_count(TimesQ2, UsersQ2, time)\n",
    "        UsersQ1_Q2.append(users_q1 + users_q2)\n",
    "\n",
    "    # Calcolo delle differenze di tempo (lt_diff) per questa simulazione\n",
    "    sim_lt_diff = {}\n",
    "    for i in range(1, len(combined_times)):\n",
    "        lt_difference = combined_times[i] - combined_times[i-1]\n",
    "        key = UsersQ1_Q2[i-1]\n",
    "        if key not in sim_lt_diff:\n",
    "            sim_lt_diff[key] = 0\n",
    "        sim_lt_diff[key] += lt_difference\n",
    "\n",
    "    # Aggiungiamo i lt_diff di questa simulazione al dizionario generale\n",
    "    for key, value in sim_lt_diff.items():\n",
    "        if key not in lt_diff_dict:\n",
    "            lt_diff_dict[key] = []\n",
    "        lt_diff_dict[key].append(value)\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza di Student\n",
    "def t_student_confidence_interval(data, confidence=0.90):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Lista per accumulare i dati delle nuove righe\n",
    "new_data = []\n",
    "\n",
    "# Calcolo dell'intervallo di confidenza e creazione delle nuove righe\n",
    "for key, lt_diffs in lt_diff_dict.items():\n",
    "    mean, lower_bound, upper_bound = t_student_confidence_interval(lt_diffs)\n",
    "    verifica = 'x' if lower_bound <= mean <= upper_bound else ''\n",
    "    new_data.append({\n",
    "        \"agents_in_the_system\": key,\n",
    "        \"lt_difference\": mean,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"verifica\": verifica\n",
    "    })\n",
    "\n",
    "# Creazione del nuovo DataFrame dalle nuove righe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Funzione per stampare la somma totale di lt_differences\n",
    "def print_total_lt_difference(df):\n",
    "    total_lt_difference = df[\"lt_difference\"].sum()\n",
    "    print(f\"La somma totale di tutti i lt_differences è: {total_lt_difference}\")\n",
    "\n",
    "# Utilizzo della funzione\n",
    "print_total_lt_difference(new_df)\n",
    "\n",
    "# Salvataggio del DataFrame in un file CSV\n",
    "new_df.to_csv(\"users_times_Config8.csv\", index=False)\n",
    "\n",
    "# Visualizzazione del nuovo DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somma totale di tutti i lt_differences è: 10025.913362364214\n",
      "    agents_in_the_system  lt_difference  lower_bound  upper_bound verifica\n",
      "0                      0    4547.550510  4472.171833  4622.929187        x\n",
      "1                      1    1857.657594  1832.744323  1882.570866        x\n",
      "2                      2    1361.291469  1340.325237  1382.257701        x\n",
      "3                      3     882.316432   862.765287   901.867577        x\n",
      "4                      4     542.175910   521.779301   562.572519        x\n",
      "5                      5     316.166680   295.044875   337.288484        x\n",
      "6                      6     187.800743   171.909400   203.692086        x\n",
      "7                      7     114.615350   101.075017   128.155682        x\n",
      "8                      8      73.337905    62.178486    84.497325        x\n",
      "9                      9      45.327510    36.578538    54.076482        x\n",
      "10                    10      27.183084    20.577940    33.788228        x\n",
      "11                    11      15.255180    10.837034    19.673326        x\n",
      "12                    12       9.362675     5.919733    12.805617        x\n",
      "13                    13       7.764822     4.437506    11.092139        x\n",
      "14                    14       6.349188     3.619397     9.078980        x\n",
      "15                    15       5.826962     1.675628     9.978297        x\n",
      "16                    16       6.883907     1.661741    12.106074        x\n",
      "17                    17       8.754223     4.589811    12.918635        x\n",
      "18                    18       8.027894     4.000048    12.055741        x\n",
      "19                    19       2.130385     1.079580     3.181189        x\n",
      "20                    20       0.134937    -0.429142     0.699016        x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Carica il DataFrame dal file CSV\n",
    "df = pd.read_csv('./results_summary_convalidation_3.csv')\n",
    "\n",
    "df = df[df[\"File\"].str.contains(\"Config10\")]\n",
    "\n",
    "# Converti le colonne in liste di float\n",
    "df[\"queueLength_Q1\"] = df[\"queueLength_Q1\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"queueLength_Q2\"] = df[\"queueLength_Q2\"].apply(lambda x: list(map(lambda y: int(float(y)), x.split(','))))\n",
    "df[\"lifeTime_change_Q1\"] = df[\"lifeTime_change_Q1\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "df[\"lifeTime_change_Q2\"] = df[\"lifeTime_change_Q2\"].apply(lambda x: list(map(float, x.split(','))))\n",
    "\n",
    "# Dizionario per accumulare i valori di lt_diff per ogni simulazione e numero di utenti\n",
    "lt_diff_dict = {}\n",
    "\n",
    "# Itera su tutte le righe del DataFrame filtrato\n",
    "for index, row in df.iterrows():\n",
    "    UsersQ1 = row[\"queueLength_Q1\"]\n",
    "    UsersQ2 = row[\"queueLength_Q2\"]\n",
    "    TimesQ1 = row[\"lifeTime_change_Q1\"]\n",
    "    TimesQ2 = row[\"lifeTime_change_Q2\"]\n",
    "\n",
    "    # Funzione per ottenere il numero di utenti in un determinato momento\n",
    "    def get_user_count(times, users, time):\n",
    "        for i, t in enumerate(times):\n",
    "            if t == time:\n",
    "                return users[i]\n",
    "            elif t > time:\n",
    "                return users[i-1]\n",
    "        return users[-1]\n",
    "\n",
    "    # Combiniamo e ordiniamo i tempi\n",
    "    combined_times = sorted(set(TimesQ1 + TimesQ2))\n",
    "\n",
    "    # Calcoliamo i valori combinati degli utenti\n",
    "    UsersQ1_Q2 = []\n",
    "    for time in combined_times:\n",
    "        users_q1 = get_user_count(TimesQ1, UsersQ1, time)\n",
    "        users_q2 = get_user_count(TimesQ2, UsersQ2, time)\n",
    "        UsersQ1_Q2.append(users_q1 + users_q2)\n",
    "\n",
    "    # Calcolo delle differenze di tempo (lt_diff) per questa simulazione\n",
    "    sim_lt_diff = {}\n",
    "    for i in range(1, len(combined_times)):\n",
    "        lt_difference = combined_times[i] - combined_times[i-1]\n",
    "        key = UsersQ1_Q2[i-1]\n",
    "        if key not in sim_lt_diff:\n",
    "            sim_lt_diff[key] = 0\n",
    "        sim_lt_diff[key] += lt_difference\n",
    "\n",
    "    # Aggiungiamo i lt_diff di questa simulazione al dizionario generale\n",
    "    for key, value in sim_lt_diff.items():\n",
    "        if key not in lt_diff_dict:\n",
    "            lt_diff_dict[key] = []\n",
    "        lt_diff_dict[key].append(value)\n",
    "\n",
    "# Funzione per calcolare l'intervallo di confidenza di Student\n",
    "def t_student_confidence_interval(data, confidence=0.90):\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "\n",
    "# Lista per accumulare i dati delle nuove righe\n",
    "new_data = []\n",
    "\n",
    "# Calcolo dell'intervallo di confidenza e creazione delle nuove righe\n",
    "for key, lt_diffs in lt_diff_dict.items():\n",
    "    mean, lower_bound, upper_bound = t_student_confidence_interval(lt_diffs)\n",
    "    verifica = 'x' if lower_bound <= mean <= upper_bound else ''\n",
    "    new_data.append({\n",
    "        \"agents_in_the_system\": key,\n",
    "        \"lt_difference\": mean,\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"verifica\": verifica\n",
    "    })\n",
    "\n",
    "# Creazione del nuovo DataFrame dalle nuove righe\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Funzione per stampare la somma totale di lt_differences\n",
    "def print_total_lt_difference(df):\n",
    "    total_lt_difference = df[\"lt_difference\"].sum()\n",
    "    print(f\"La somma totale di tutti i lt_differences è: {total_lt_difference}\")\n",
    "\n",
    "# Utilizzo della funzione\n",
    "print_total_lt_difference(new_df)\n",
    "\n",
    "# Salvataggio del DataFrame in un file CSV\n",
    "new_df.to_csv(\"users_times_Config10.csv\", index=False)\n",
    "\n",
    "# Visualizzazione del nuovo DataFrame\n",
    "print(new_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inifile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
